#!/usr/bin/env python3
"""
å®šæœŸå®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
ä¸å‹•ç”£ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åé›†ãƒ»å‡¦ç†ã‚’å®šæœŸå®Ÿè¡Œã™ã‚‹
"""

import schedule
import time
import subprocess
import logging
import os
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List
import threading
import signal
import sys

class RealEstateScheduler:
    def __init__(self, config_file='scheduler_config.json'):
        self.config_file = config_file
        self.running = False
        self.threads = []
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('scheduler.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        self.config = self.load_config()
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def load_config(self) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        default_config = {
            'scraping': {
                'enabled': True,
                'schedule': '0 6 * * *',  # æ¯æ—¥æœ6æ™‚
                'description': 'Daily scraping at 6 AM'
            },
            'deduplication': {
                'enabled': True,
                'schedule': '0 7 * * *',  # æ¯æ—¥æœ7æ™‚
                'description': 'Daily deduplication at 7 AM'
            },
            'price_history': {
                'enabled': True,
                'schedule': '0 8 * * *',  # æ¯æ—¥æœ8æ™‚
                'description': 'Daily price history update at 8 AM'
            },
            'database_cleanup': {
                'enabled': True,
                'schedule': '0 2 * * 0',  # æ¯é€±æ—¥æ›œæ—¥åˆå‰2æ™‚
                'description': 'Weekly database cleanup'
            },
            'backup': {
                'enabled': True,
                'schedule': '0 3 * * *',  # æ¯æ—¥åˆå‰3æ™‚
                'description': 'Daily database backup'
            },
            'notification': {
                'enabled': False,
                'email': '',
                'webhook_url': ''
            },
            'limits': {
                'max_runtime_minutes': 60,
                'max_retries': 3,
                'retry_delay_minutes': 5
            }
        }
        
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¨ãƒãƒ¼ã‚¸
                    default_config.update(user_config)
            except Exception as e:
                self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            self.save_config(default_config)
        
        return default_config
    
    def save_config(self, config: Dict):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_command(self, command: str, description: str, timeout_minutes: int = 30) -> bool:
        """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
        self.logger.info(f"ğŸ“‹ å®Ÿè¡Œé–‹å§‹: {description}")
        start_time = datetime.now()
        
        try:
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=timeout_minutes * 60
            )
            
            duration = datetime.now() - start_time
            
            if result.returncode == 0:
                self.logger.info(f"âœ… å®Œäº†: {description} ({duration.total_seconds():.1f}ç§’)")
                if result.stdout:
                    self.logger.debug(f"å‡ºåŠ›: {result.stdout}")
                return True
            else:
                self.logger.error(f"âŒ å¤±æ•—: {description} (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode})")
                if result.stderr:
                    self.logger.error(f"ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {description} ({timeout_minutes}åˆ†)")
            return False
        except Exception as e:
            self.logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {description} - {e}")
            return False
    
    def run_with_retry(self, command: str, description: str, max_retries: int = 3) -> bool:
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
        for attempt in range(max_retries):
            if attempt > 0:
                self.logger.info(f"ğŸ”„ ãƒªãƒˆãƒ©ã‚¤ {attempt}/{max_retries}: {description}")
                time.sleep(self.config['limits']['retry_delay_minutes'] * 60)
            
            if self.run_command(command, description, self.config['limits']['max_runtime_minutes']):
                return True
        
        self.logger.error(f"âŒ æœ€çµ‚å¤±æ•—: {description} (æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«åˆ°é”)")
        return False
    
    def scraping_job(self):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¸ãƒ§ãƒ–"""
        if not self.config['scraping']['enabled']:
            return
        
        self.logger.info("ğŸ  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¸ãƒ§ãƒ–é–‹å§‹")
        
        # æ”¹è‰¯ç‰ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ä½¿ç”¨
        success = self.run_with_retry(
            'python3 enhanced_scraper.py',
            'Enhanced scraping job',
            self.config['limits']['max_retries']
        )
        
        if success:
            self.record_job_execution('scraping', True)
            self.send_notification('ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†', 'success')
        else:
            self.record_job_execution('scraping', False)
            self.send_notification('ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—', 'error')
    
    def deduplication_job(self):
        """é‡è¤‡æ’é™¤ã‚¸ãƒ§ãƒ–"""
        if not self.config['deduplication']['enabled']:
            return
        
        self.logger.info("ğŸ”„ é‡è¤‡æ’é™¤ã‚¸ãƒ§ãƒ–é–‹å§‹")
        
        # è‡ªå‹•é‡è¤‡æ’é™¤ã‚’å®Ÿè¡Œ
        success = self.run_with_retry(
            'python3 -c "from deduplication_engine import DeduplicationEngine; engine = DeduplicationEngine(); engine.run_deduplication(auto_merge=True)"',
            'Deduplication job',
            self.config['limits']['max_retries']
        )
        
        if success:
            self.record_job_execution('deduplication', True)
            self.send_notification('é‡è¤‡æ’é™¤å®Œäº†', 'success')
        else:
            self.record_job_execution('deduplication', False)
            self.send_notification('é‡è¤‡æ’é™¤å¤±æ•—', 'error')
    
    def price_history_job(self):
        """ä¾¡æ ¼å±¥æ­´æ›´æ–°ã‚¸ãƒ§ãƒ–"""
        if not self.config['price_history']['enabled']:
            return
        
        self.logger.info("ğŸ“ˆ ä¾¡æ ¼å±¥æ­´æ›´æ–°ã‚¸ãƒ§ãƒ–é–‹å§‹")
        
        success = self.run_with_retry(
            'python3 -c "from price_history_tracker import PriceHistoryTracker; tracker = PriceHistoryTracker(); tracker.update_all_price_history()"',
            'Price history update job',
            self.config['limits']['max_retries']
        )
        
        if success:
            self.record_job_execution('price_history', True)
            self.send_notification('ä¾¡æ ¼å±¥æ­´æ›´æ–°å®Œäº†', 'success')
        else:
            self.record_job_execution('price_history', False)
            self.send_notification('ä¾¡æ ¼å±¥æ­´æ›´æ–°å¤±æ•—', 'error')
    
    def database_cleanup_job(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¸ãƒ§ãƒ–"""
        if not self.config['database_cleanup']['enabled']:
            return
        
        self.logger.info("ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        try:
            conn = sqlite3.connect('realestate.db')
            cursor = conn.cursor()
            
            # å¤ã„ä¾¡æ ¼å±¥æ­´ã‚’å‰Šé™¤ï¼ˆ90æ—¥ä»¥ä¸Šå‰ï¼‰
            cursor.execute('''
                DELETE FROM price_history 
                WHERE updated_at < datetime('now', '-90 days')
            ''')
            
            # ç„¡åŠ¹ãªãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šå‰ï¼‰
            cursor.execute('''
                DELETE FROM property_listings 
                WHERE is_active = 0 AND updated_at < datetime('now', '-30 days')
            ''')
            
            # VACUUMã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æœ€é©åŒ–
            cursor.execute('VACUUM')
            
            conn.commit()
            conn.close()
            
            self.logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            self.record_job_execution('database_cleanup', True)
            self.send_notification('ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†', 'success')
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            self.record_job_execution('database_cleanup', False)
            self.send_notification('ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—', 'error')
    
    def backup_job(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¸ãƒ§ãƒ–"""
        if not self.config['backup']['enabled']:
            return
        
        self.logger.info("ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¸ãƒ§ãƒ–é–‹å§‹")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = 'backups'
        os.makedirs(backup_dir, exist_ok=True)
        
        backup_file = f"{backup_dir}/realestate_backup_{timestamp}.db"
        
        success = self.run_command(
            f'cp realestate.db {backup_file}',
            f'Database backup to {backup_file}'
        )
        
        if success:
            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
            cutoff_date = datetime.now() - timedelta(days=7)
            for file in os.listdir(backup_dir):
                if file.startswith('realestate_backup_') and file.endswith('.db'):
                    file_path = os.path.join(backup_dir, file)
                    if os.path.getctime(file_path) < cutoff_date.timestamp():
                        os.remove(file_path)
                        self.logger.info(f"ğŸ—‘ï¸  å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤: {file}")
            
            self.record_job_execution('backup', True)
            self.send_notification('ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†', 'success')
        else:
            self.record_job_execution('backup', False)
            self.send_notification('ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—', 'error')
    
    def record_job_execution(self, job_name: str, success: bool):
        """ã‚¸ãƒ§ãƒ–å®Ÿè¡Œè¨˜éŒ²"""
        try:
            conn = sqlite3.connect('realestate.db')
            cursor = conn.cursor()
            
            # ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã‘ã‚Œã°ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS job_execution_log (
                    id INTEGER PRIMARY KEY,
                    job_name TEXT NOT NULL,
                    success BOOLEAN NOT NULL,
                    executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            cursor.execute('''
                INSERT INTO job_execution_log (job_name, success)
                VALUES (?, ?)
            ''', (job_name, success))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"ã‚¸ãƒ§ãƒ–å®Ÿè¡Œè¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def send_notification(self, message: str, level: str = 'info'):
        """é€šçŸ¥é€ä¿¡"""
        if not self.config['notification']['enabled']:
            return
        
        # ç°¡å˜ãªé€šçŸ¥å®Ÿè£…ï¼ˆæ‹¡å¼µå¯èƒ½ï¼‰
        notification_data = {
            'message': message,
            'level': level,
            'timestamp': datetime.now().isoformat(),
            'hostname': os.uname().nodename if hasattr(os, 'uname') else 'unknown'
        }
        
        self.logger.info(f"ğŸ“¢ é€šçŸ¥: {message}")
        
        # Webhookã‚„Emailã®å®Ÿè£…ã¯ã“ã“ã«è¿½åŠ 
        # if self.config['notification']['webhook_url']:
        #     self.send_webhook_notification(notification_data)
    
    def setup_schedules(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨­å®š"""
        self.logger.info("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šä¸­...")
        
        # å„ã‚¸ãƒ§ãƒ–ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ç™»éŒ²
        if self.config['scraping']['enabled']:
            schedule.every().day.at("06:00").do(self.scraping_job)
            self.logger.info("ğŸ“‹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: æ¯æ—¥ 06:00")
        
        if self.config['deduplication']['enabled']:
            schedule.every().day.at("07:00").do(self.deduplication_job)
            self.logger.info("ğŸ”„ é‡è¤‡æ’é™¤: æ¯æ—¥ 07:00")
        
        if self.config['price_history']['enabled']:
            schedule.every().day.at("08:00").do(self.price_history_job)
            self.logger.info("ğŸ“ˆ ä¾¡æ ¼å±¥æ­´: æ¯æ—¥ 08:00")
        
        if self.config['database_cleanup']['enabled']:
            schedule.every().sunday.at("02:00").do(self.database_cleanup_job)
            self.logger.info("ğŸ§¹ DB cleanup: æ¯é€±æ—¥æ›œæ—¥ 02:00")
        
        if self.config['backup']['enabled']:
            schedule.every().day.at("03:00").do(self.backup_job)
            self.logger.info("ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: æ¯æ—¥ 03:00")
        
        self.logger.info("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šå®Œäº†")
    
    def signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        self.logger.info(f"ğŸ›‘ ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ä¸­...")
        self.running = False
    
    def run(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
        self.logger.info("ğŸš€ ä¸å‹•ç”£ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
        
        self.setup_schedules()
        self.running = True
        
        # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’è¡¨ç¤º
        self.show_next_runs()
        
        try:
            while self.running:
                schedule.run_pending()
                time.sleep(60)  # 1åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
                
        except KeyboardInterrupt:
            self.logger.info("âš ï¸  ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã‚’æ¤œå‡º")
        finally:
            self.logger.info("ğŸ‘‹ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def show_next_runs(self):
        """æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’è¡¨ç¤º"""
        jobs = schedule.jobs
        if jobs:
            self.logger.info("â° æ¬¡å›å®Ÿè¡Œäºˆå®š:")
            for job in jobs:
                self.logger.info(f"  - {job.job_func.__name__}: {job.next_run}")
    
    def run_job_now(self, job_name: str):
        """æŒ‡å®šã•ã‚ŒãŸã‚¸ãƒ§ãƒ–ã‚’å³åº§ã«å®Ÿè¡Œ"""
        job_methods = {
            'scraping': self.scraping_job,
            'deduplication': self.deduplication_job,
            'price_history': self.price_history_job,
            'database_cleanup': self.database_cleanup_job,
            'backup': self.backup_job
        }
        
        if job_name in job_methods:
            self.logger.info(f"ğŸ”§ æ‰‹å‹•å®Ÿè¡Œ: {job_name}")
            job_methods[job_name]()
        else:
            self.logger.error(f"âŒ ä¸æ˜ãªã‚¸ãƒ§ãƒ–: {job_name}")
    
    def show_job_history(self, limit: int = 10):
        """ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ã‚’è¡¨ç¤º"""
        try:
            conn = sqlite3.connect('realestate.db')
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT job_name, success, executed_at
                FROM job_execution_log
                ORDER BY executed_at DESC
                LIMIT ?
            ''', (limit,))
            
            history = cursor.fetchall()
            
            if history:
                print(f"\nğŸ“Š ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ (æœ€æ–°{limit}ä»¶):")
                print("ã‚¸ãƒ§ãƒ–å          | çµæœ | å®Ÿè¡Œæ™‚åˆ»")
                print("-" * 50)
                for job_name, success, executed_at in history:
                    status = "âœ…" if success else "âŒ"
                    print(f"{job_name:15s} | {status:4s} | {executed_at}")
            else:
                print("ğŸ“Š ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“")
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"ã‚¸ãƒ§ãƒ–å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    scheduler = RealEstateScheduler()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'run':
            scheduler.run()
        elif command == 'run-job' and len(sys.argv) > 2:
            scheduler.run_job_now(sys.argv[2])
        elif command == 'history':
            scheduler.show_job_history()
        elif command == 'next':
            scheduler.setup_schedules()
            scheduler.show_next_runs()
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python3 scheduler.py run           # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹")
            print("  python3 scheduler.py run-job JOB   # æŒ‡å®šã‚¸ãƒ§ãƒ–ã‚’å³åº§ã«å®Ÿè¡Œ")
            print("  python3 scheduler.py history       # ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ã‚’è¡¨ç¤º")
            print("  python3 scheduler.py next          # æ¬¡å›å®Ÿè¡Œäºˆå®šã‚’è¡¨ç¤º")
            print()
            print("åˆ©ç”¨å¯èƒ½ãªã‚¸ãƒ§ãƒ–:")
            print("  - scraping")
            print("  - deduplication")
            print("  - price_history")
            print("  - database_cleanup")
            print("  - backup")
    else:
        print("ğŸ“… ä¸å‹•ç”£ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼")
        print("=" * 30)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python3 scheduler.py run           # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹")
        print("  python3 scheduler.py run-job JOB   # æŒ‡å®šã‚¸ãƒ§ãƒ–ã‚’å³åº§ã«å®Ÿè¡Œ")
        print("  python3 scheduler.py history       # ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå±¥æ­´ã‚’è¡¨ç¤º")
        print("  python3 scheduler.py next          # æ¬¡å›å®Ÿè¡Œäºˆå®šã‚’è¡¨ç¤º")

if __name__ == '__main__':
    main()